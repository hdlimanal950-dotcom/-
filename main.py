#!/usr/bin/env python3
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ZAJMIL AI CHEF - Complete Integrated System v2.2.0 [RENDER PRODUCTION - V1 API]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ù†Ø¸Ø§Ù… Ù…ØªÙƒØ§Ù…Ù„ Ù„ØªÙˆÙ„ÙŠØ¯ ÙˆÙ†Ø´Ø± ÙˆØµÙØ§Øª Ø§Ù„Ø·Ø¨Ø® Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ

Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© v2.2 [CRITICAL RENDER FIXES]:
âœ… Ø¥Ø¬Ø¨Ø§Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… v1 API (Ø§Ù„Ù…Ø³ØªÙ‚Ø±) Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† v1beta
âœ… ØªØ·Ø¨ÙŠØ¹ Ø°ÙƒÙŠ Ù…ØªÙ‚Ø¯Ù… Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¹ fallback
âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ø¬Ù…ÙŠØ¹ Ø£Ø®Ø·Ø§Ø¡ API Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
âœ… Ø§ÙƒØªØ´Ø§Ù ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©
âœ… Ø§Ø³ØªÙ‚Ø±Ø§Ø± ÙƒØ§Ù…Ù„ Ø¹Ù„Ù‰ Render Ø¨Ø¯ÙˆÙ† timeout

Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø­Ø±Ø¬Ø© v2.2:
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¨Ø§Ø´Ø± Ù„Ù€ REST API endpoint v1
- ØªØ·Ø¨ÙŠØ¹ Ù…Ø­Ø³Ù‘Ù† ÙŠØ¯Ø¹Ù… Ø¬Ù…ÙŠØ¹ ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ø£Ø³Ù…Ø§Ø¡
- retry Ù…Ø¹ intelligent backoff
- error recovery Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙØ´Ù„

Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
  python main.py --mode once              # Ù†Ø´Ø± ÙˆØµÙØ© ÙˆØ§Ø­Ø¯Ø©
  python main.py --mode continuous        # Ù†Ø´Ø± Ù…Ø³ØªÙ…Ø±
  python main.py --mode report            # ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡
  
Ù…ØªØºÙŠØ±Ø§Øª Render Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:
  - GEMINI_API_KEY
  - BLOGGER_BLOG_ID
  - TOKEN_JSON (Ù…Ø­ØªÙˆÙ‰ Ù…Ù„Ù token.json ÙƒÙ†Øµ JSON)
  - CLIENT_SECRET_JSON (Ù…Ø­ØªÙˆÙ‰ Ù…Ù„Ù client_secret.json ÙƒÙ†Øµ JSON)
  
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import json
import time
import logging
import random
import re
import pickle
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from collections import defaultdict, Counter
from logging.handlers import RotatingFileHandler
from xml.etree import ElementTree as ET

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORTS - Google APIs & AI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

try:
    import google.generativeai as genai
    GENAI_AVAILABLE = True
except ImportError:
    GENAI_AVAILABLE = False
    print("âŒ ERROR: google-generativeai not installed")
    print("   Install: pip install google-generativeai")
    sys.exit(1)

try:
    from google.oauth2.credentials import Credentials
    from google_auth_oauthlib.flow import InstalledAppFlow
    from google.auth.transport.requests import Request
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
    GOOGLE_API_AVAILABLE = True
except ImportError:
    GOOGLE_API_AVAILABLE = False
    print("âŒ ERROR: Google API libraries not installed")
    print("   Install: pip install google-auth google-auth-oauthlib google-api-python-client")
    sys.exit(1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RENDER ENVIRONMENT SETUP - CRITICAL FOR CLOUD DEPLOYMENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def setup_render_environment():
    """
    Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ù„Ù€ Render
    
    ÙŠÙ‚ÙˆÙ… Ø¨Ù€:
    1. Ù‚Ø±Ø§Ø¡Ø© TOKEN_JSON Ùˆ CLIENT_SECRET_JSON Ù…Ù† Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
    2. ÙƒØªØ§Ø¨ØªÙ‡Ø§ ÙƒÙ…Ù„ÙØ§Øª Ù…Ø¤Ù‚ØªØ© ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
    3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    
    Returns:
        Tuple[Path, Path]: Ù…Ø³Ø§Ø±Ø§Øª token.json Ùˆ client_secret.json
    """
    print("\n" + "=" * 80)
    print("ğŸ”§ RENDER ENVIRONMENT SETUP")
    print("=" * 80)
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ (Render ÙŠØ³ØªØ®Ø¯Ù… /tmp Ù„Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©)
    is_render = os.getenv("RENDER", "false").lower() == "true"
    base_path = Path("/tmp") if is_render else Path(__file__).resolve().parent
    
    print(f"ğŸ“ Base Path: {base_path}")
    print(f"ğŸŒ Render Mode: {is_render}")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ data Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    data_dir = base_path / "data"
    data_dir.mkdir(exist_ok=True, parents=True)
    print(f"âœ… Data directory created: {data_dir}")
    
    # â•â•â• Ù…Ø¹Ø§Ù„Ø¬Ø© TOKEN_JSON â•â•â•
    token_path = base_path / "token.json"
    token_json_env = os.getenv("TOKEN_JSON", "")
    
    if token_json_env:
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© JSON Ù‚Ø¨Ù„ Ø§Ù„ÙƒØªØ§Ø¨Ø©
            token_data = json.loads(token_json_env)
            
            with open(token_path, 'w', encoding='utf-8') as f:
                json.dump(token_data, f, indent=2)
            
            print(f"âœ… Token file created from environment: {token_path}")
        except json.JSONDecodeError as e:
            print(f"âš ï¸ WARNING: Invalid TOKEN_JSON format: {e}")
            print("   Authentication may fail. Ensure TOKEN_JSON is valid JSON.")
    else:
        if not token_path.exists():
            print("âš ï¸ WARNING: TOKEN_JSON not found in environment variables")
            print("   File will be created after first OAuth flow")
    
    # â•â•â• Ù…Ø¹Ø§Ù„Ø¬Ø© CLIENT_SECRET_JSON â•â•â•
    client_secret_path = base_path / "client_secret.json"
    client_secret_env = os.getenv("CLIENT_SECRET_JSON", "")
    
    if client_secret_env:
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© JSON Ù‚Ø¨Ù„ Ø§Ù„ÙƒØªØ§Ø¨Ø©
            client_data = json.loads(client_secret_env)
            
            with open(client_secret_path, 'w', encoding='utf-8') as f:
                json.dump(client_data, f, indent=2)
            
            print(f"âœ… Client secret file created from environment: {client_secret_path}")
        except json.JSONDecodeError as e:
            print(f"âš ï¸ WARNING: Invalid CLIENT_SECRET_JSON format: {e}")
    else:
        print("â„¹ï¸ INFO: CLIENT_SECRET_JSON not provided (will use CLIENT_ID/SECRET directly)")
    
    print("=" * 80 + "\n")
    
    return token_path, client_secret_path, base_path

# ØªÙ†ÙÙŠØ° Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ ÙÙˆØ±Ø§Ù‹ Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬
TOKEN_PATH, CLIENT_SECRET_PATH, BASE_PATH = setup_render_environment()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION WITH FULL RENDER SUPPORT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class Config:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù…Ø¹ Ø¯Ø¹Ù… ÙƒØ§Ù…Ù„ Ù„Ù€ Render"""
    
    # Gemini AI - Ø§Ø³ØªØ®Ø¯Ø§Ù… Flash ÙƒÙ†Ù…ÙˆØ°Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„Ø³Ø±Ø¹Ø©
    GEMINI_API_KEY: str = os.getenv("GEMINI_API_KEY", "")
    GEMINI_MODEL: str = os.getenv("GEMINI_MODEL", "gemini-1.5-flash-latest")
    GEMINI_TEMPERATURE: float = float(os.getenv("GEMINI_TEMPERATURE", "0.9"))
    GEMINI_MAX_TOKENS: int = int(os.getenv("GEMINI_MAX_TOKENS", "8000"))
    GEMINI_TIMEOUT: int = int(os.getenv("GEMINI_TIMEOUT", "120"))
    GEMINI_MAX_RETRIES: int = int(os.getenv("GEMINI_MAX_RETRIES", "5"))
    
    # Force v1 API (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ Ù„Ù€ Render)
    FORCE_V1_API: bool = os.getenv("FORCE_V1_API", "true").lower() == "true"
    
    # Blogger API
    BLOGGER_BLOG_ID: str = os.getenv("BLOGGER_BLOG_ID", "")
    BLOGGER_CLIENT_ID: str = os.getenv("BLOGGER_CLIENT_ID", "")
    BLOGGER_CLIENT_SECRET: str = os.getenv("BLOGGER_CLIENT_SECRET", "")
    BLOGGER_SCOPES: List[str] = field(default_factory=lambda: [
        "https://www.googleapis.com/auth/blogger"
    ])
    
    # Content Settings
    CONTENT_CATEGORIES: List[str] = field(default_factory=lambda: 
        json.loads(os.getenv("CONTENT_CATEGORIES", json.dumps([
            "Ø­Ù„ÙˆÙŠØ§Øª Ø¹Ø±Ø¨ÙŠØ©", "Ù…Ø¹Ø¬Ù†Ø§Øª", "ÙƒÙŠÙƒ ÙˆØªÙˆØ±ØªØ§Øª", "Ø¨Ø³ÙƒÙˆÙŠØª ÙˆÙƒÙˆÙƒÙŠØ²",
            "Ø­Ù„ÙˆÙŠØ§Øª Ø¨Ø§Ø±Ø¯Ø©", "ÙØ·Ø§Ø¦Ø± ÙˆÙ…Ø®Ø¨ÙˆØ²Ø§Øª", "Ø­Ù„ÙˆÙŠØ§Øª ØµØ­ÙŠØ©", "Ø£Ø·Ø¨Ø§Ù‚ Ø±Ù…Ø¶Ø§Ù†ÙŠØ©"
        ])))
    )
    
    MIN_RECIPE_INGREDIENTS: int = int(os.getenv("MIN_RECIPE_INGREDIENTS", "5"))
    MIN_RECIPE_STEPS: int = int(os.getenv("MIN_RECIPE_STEPS", "6"))
    TARGET_WORD_COUNT: int = int(os.getenv("TARGET_WORD_COUNT", "1200"))
    
    # SEO - ØªØ­Ø³ÙŠÙ†Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ø¬Ù„Ø¨ Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ø³Ø±ÙŠØ¹Ø©
    PRIMARY_KEYWORDS: List[str] = field(default_factory=lambda: 
        json.loads(os.getenv("PRIMARY_KEYWORDS", json.dumps([
            "ÙˆØµÙØ§Øª Ø·Ø¨Ø®", "Ø­Ù„ÙˆÙŠØ§Øª Ø³Ù‡Ù„Ø©", "Ø·Ø±ÙŠÙ‚Ø© Ø¹Ù…Ù„", "ÙˆØµÙØ§Øª Ù…Ù†Ø²Ù„ÙŠØ©",
            "Ø­Ù„ÙˆÙŠØ§Øª Ù„Ø°ÙŠØ°Ø©", "Ù…Ø·Ø¨Ø® Ø¹Ø±Ø¨ÙŠ", "ÙˆØµÙØ§Øª Ø³Ø±ÙŠØ¹Ø©", "Ø£Ø·Ø¨Ø§Ù‚ Ø´Ù‡ÙŠØ©"
        ])))
    )
    
    META_DESCRIPTION_LENGTH: int = int(os.getenv("META_DESCRIPTION_LENGTH", "160"))
    ENABLE_SCHEMA_MARKUP: bool = os.getenv("ENABLE_SCHEMA_MARKUP", "true").lower() == "true"
    
    # ØªØ­Ø³ÙŠÙ†Ø§Øª SEO Ù„Ø¬Ù„Ø¨ Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ø£Ø³Ø±Ø¹
    ENABLE_RICH_SNIPPETS: bool = os.getenv("ENABLE_RICH_SNIPPETS", "true").lower() == "true"
    ENABLE_SOCIAL_META_TAGS: bool = os.getenv("ENABLE_SOCIAL_META_TAGS", "true").lower() == "true"
    AGGRESSIVE_SEO_MODE: bool = os.getenv("AGGRESSIVE_SEO_MODE", "true").lower() == "true"
    
    # Publishing Strategy
    PUBLISH_INTERVAL_HOURS: int = int(os.getenv("PUBLISH_INTERVAL_HOURS", "24"))
    AUTO_PUBLISH: bool = os.getenv("AUTO_PUBLISH", "true").lower() == "true"
    DRAFT_MODE: bool = os.getenv("DRAFT_MODE", "false").lower() == "true"
    
    # Dynamic Article Count Calculation
    MIN_VIEWS_FETCH_HOURS: int = int(os.getenv("MIN_VIEWS_FETCH_HOURS", "48"))
    ARTICLE_SAFETY_FACTOR: float = float(os.getenv("ARTICLE_SAFETY_FACTOR", "0.8"))
    MAX_ARTICLES_LIMIT: int = int(os.getenv("MAX_ARTICLES_LIMIT", "100"))
    MIN_ARTICLES_LIMIT: int = int(os.getenv("MIN_ARTICLES_LIMIT", "1"))
    ENABLE_DYNAMIC_ARTICLE_COUNT: bool = os.getenv("ENABLE_DYNAMIC_ARTICLE_COUNT", "true").lower() == "true"
    FIXED_ARTICLE_COUNT: int = int(os.getenv("FIXED_ARTICLE_COUNT", "50"))
    
    # Render Specific Settings
    RENDER_INSTANCE_ID: str = os.getenv("RENDER_INSTANCE_ID", "")
    RENDER_SERVICE_NAME: str = os.getenv("RENDER_SERVICE_NAME", "")
    RENDER_GIT_COMMIT: str = os.getenv("RENDER_GIT_COMMIT", "")
    IS_RENDER_ENV: bool = os.getenv("RENDER", "false").lower() == "true"
    
    # Paths - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© Ù…Ù† setup_render_environment
    BASE_DIR: Path = BASE_PATH
    CREDENTIALS_PATH: Path = TOKEN_PATH
    CLIENT_SECRET_FILE: Path = CLIENT_SECRET_PATH
    DATA_DIR: Path = field(init=False)
    LOG_FILE: str = os.getenv("LOG_FILE", "zajmil.log")
    PERFORMANCE_FILE: str = os.getenv("PERFORMANCE_FILE", "performance.json")
    
    def __post_init__(self):
        self.DATA_DIR = self.BASE_DIR / "data"
        self.DATA_DIR.mkdir(exist_ok=True, parents=True)
    
    def calculate_optimal_article_count(self) -> int:
        """Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ø£Ù…Ø«Ù„"""
        if not self.ENABLE_DYNAMIC_ARTICLE_COUNT:
            return self.FIXED_ARTICLE_COUNT
        
        raw_count = (self.MIN_VIEWS_FETCH_HOURS / self.PUBLISH_INTERVAL_HOURS) * self.ARTICLE_SAFETY_FACTOR
        calculated_count = int(raw_count) + (1 if raw_count % 1 > 0 else 0)
        final_count = max(self.MIN_ARTICLES_LIMIT, min(calculated_count, self.MAX_ARTICLES_LIMIT))
        
        return final_count
    
    def validate(self) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø´Ø§Ù…Ù„ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"""
        errors = []
        
        if not self.GEMINI_API_KEY:
            errors.append("âŒ GEMINI_API_KEY is required")
        
        if not self.GEMINI_MODEL:
            errors.append("âŒ GEMINI_MODEL is required")
        
        if not self.BLOGGER_BLOG_ID:
            errors.append("âŒ BLOGGER_BLOG_ID is required")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©
        has_token = self.CREDENTIALS_PATH.exists() or os.getenv("TOKEN_JSON")
        has_client_creds = (self.BLOGGER_CLIENT_ID and self.BLOGGER_CLIENT_SECRET) or \
                          self.CLIENT_SECRET_FILE.exists() or os.getenv("CLIENT_SECRET_JSON")
        
        if not has_token and not has_client_creds:
            errors.append("âŒ Authentication credentials missing")
            errors.append("   Provide either: TOKEN_JSON or (BLOGGER_CLIENT_ID + BLOGGER_CLIENT_SECRET)")
        
        if self.MIN_VIEWS_FETCH_HOURS < self.PUBLISH_INTERVAL_HOURS:
            errors.append("âŒ MIN_VIEWS_FETCH_HOURS must be >= PUBLISH_INTERVAL_HOURS")
        
        if self.ARTICLE_SAFETY_FACTOR <= 0 or self.ARTICLE_SAFETY_FACTOR > 2:
            errors.append("âŒ ARTICLE_SAFETY_FACTOR must be between 0 and 2")
        
        if errors:
            for error in errors:
                print(error)
            raise ValueError("Configuration validation failed")
        
        return True

config = Config()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LOGGING SYSTEM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ColoredFormatter(logging.Formatter):
    COLORS = {
        'DEBUG': '\033[36m', 'INFO': '\033[32m', 'WARNING': '\033[33m',
        'ERROR': '\033[31m', 'CRITICAL': '\033[35m', 'RESET': '\033[0m'
    }
    
    def format(self, record):
        color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
        record.levelname = f"{color}{record.levelname:8}{self.COLORS['RESET']}"
        return super().format(record)

def setup_logger():
    logger = logging.getLogger("ZajmilAI")
    logger.setLevel(logging.DEBUG)
    logger.handlers.clear()
    
    console = logging.StreamHandler(sys.stdout)
    console.setLevel(logging.INFO)
    console.setFormatter(ColoredFormatter(
        '%(asctime)s | %(levelname)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    ))
    
    log_path = config.BASE_DIR / config.LOG_FILE
    file_handler = RotatingFileHandler(
        log_path, maxBytes=10*1024*1024, backupCount=5, encoding='utf-8'
    )
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(logging.Formatter(
        '%(asctime)s | %(levelname)-8s | %(funcName)s | %(message)s'
    ))
    
    logger.addHandler(console)
    logger.addHandler(file_handler)
    return logger

logger = setup_logger()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA MODELS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class Recipe:
    """Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙˆØµÙØ© Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª SEO Ù…ØªÙ‚Ø¯Ù…Ø©"""
    title: str
    category: str
    description: str
    ingredients: List[str]
    steps: List[str]
    prep_time: int
    cook_time: int
    servings: int
    difficulty: str
    meta_description: str = ""
    keywords: List[str] = field(default_factory=list)
    tags: List[str] = field(default_factory=list)
    post_id: Optional[str] = None
    post_url: Optional[str] = None
    published_at: Optional[datetime] = None
    seo_score: float = 0.0
    word_count: int = 0
    
    def to_html(self) -> str:
        """ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆØµÙØ© Ø¥Ù„Ù‰ HTML Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª SEO Ù…ØªÙ‚Ø¯Ù…Ø©"""
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        total_time = self.prep_time + self.cook_time
        
        # Ø¨Ù†Ø§Ø¡ Schema.org Markup Ù„Ù„Ø¸Ù‡ÙˆØ± ÙÙŠ Rich Snippets
        schema_markup = ""
        if config.ENABLE_SCHEMA_MARKUP:
            schema_markup = f"""
<script type="application/ld+json">
{{
  "@context": "https://schema.org/",
  "@type": "Recipe",
  "name": "{self.title}",
  "description": "{self.meta_description}",
  "author": {{
    "@type": "Person",
    "name": "ÙØ±ÙŠÙ‚ Ø²Ø¬Ù…ÙŠÙ„"
  }},
  "datePublished": "{datetime.now().isoformat()}",
  "prepTime": "PT{self.prep_time}M",
  "cookTime": "PT{self.cook_time}M",
  "totalTime": "PT{total_time}M",
  "recipeYield": "{self.servings} Ø£Ø´Ø®Ø§Øµ",
  "recipeCategory": "{self.category}",
  "recipeCuisine": "Ø¹Ø±Ø¨ÙŠ",
  "keywords": "{', '.join(self.keywords)}",
  "recipeIngredient": {json.dumps(self.ingredients, ensure_ascii=False)},
  "recipeInstructions": {json.dumps([{"@type": "HowToStep", "text": step} for step in self.steps], ensure_ascii=False)}
}}
</script>
"""
        
        # Social Meta Tags Ù„Ù„Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©
        social_meta = ""
        if config.ENABLE_SOCIAL_META_TAGS:
            social_meta = f"""
<meta property="og:title" content="{self.title}" />
<meta property="og:description" content="{self.meta_description}" />
<meta property="og:type" content="article" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="{self.title}" />
<meta name="twitter:description" content="{self.meta_description}" />
"""
        
        # Ø¨Ù†Ø§Ø¡ HTML Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        html = f"""{schema_markup}{social_meta}
<article class="recipe-post" itemscope itemtype="https://schema.org/Recipe">
    <div class="recipe-header">
        <h1 itemprop="name">{self.title}</h1>
        <p class="recipe-meta">
            <span itemprop="prepTime" content="PT{self.prep_time}M">â±ï¸ Ø§Ù„ØªØ­Ø¶ÙŠØ±: {self.prep_time} Ø¯Ù‚ÙŠÙ‚Ø©</span> | 
            <span itemprop="cookTime" content="PT{self.cook_time}M">ğŸ”¥ Ø§Ù„Ø·Ù‡ÙŠ: {self.cook_time} Ø¯Ù‚ÙŠÙ‚Ø©</span> | 
            <span itemprop="recipeYield">ğŸ‘¥ {self.servings} Ø£Ø´Ø®Ø§Øµ</span> | 
            <span>ğŸ“Š {self.difficulty}</span>
        </p>
        <meta itemprop="recipeCategory" content="{self.category}" />
        <meta itemprop="recipeCuisine" content="Ø¹Ø±Ø¨ÙŠ" />
    </div>
    
    <div class="recipe-description" itemprop="description">
        <p>{self.description}</p>
    </div>
    
    <div class="recipe-ingredients">
        <h2>ğŸ¥˜ Ø§Ù„Ù…Ù‚Ø§Ø¯ÙŠØ±</h2>
        <ul>
"""
        for ing in self.ingredients:
            html += f'            <li itemprop="recipeIngredient">{ing}</li>\n'
        
        html += """        </ul>
    </div>
    
    <div class="recipe-steps">
        <h2>ğŸ‘¨â€ğŸ³ Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ø¶ÙŠØ±</h2>
        <ol itemprop="recipeInstructions">
"""
        for idx, step in enumerate(self.steps, 1):
            html += f'            <li itemprop="step" itemscope itemtype="https://schema.org/HowToStep"><span itemprop="text">{step}</span></li>\n'
        
        html += f"""        </ol>
    </div>
    
    <div class="recipe-footer">
        <p>ğŸ’¡ <strong>Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ù†Ø¬Ø§Ø­:</strong> Ø§ØªØ¨Ø¹ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¨Ø¯Ù‚Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬</p>
        <p>â­ Ø´Ø§Ø±Ùƒ ØªØ¬Ø±Ø¨ØªÙƒ ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª!</p>
        <p>ğŸ”– Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©: <span itemprop="keywords">{', '.join(self.keywords[:5])}</span></p>
    </div>
</article>

<style>
.recipe-post {{
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    line-height: 1.8;
    color: #333;
    max-width: 800px;
    margin: 0 auto;
    padding: 20px;
    background: #fff;
}}

.recipe-header h1 {{
    color: #2c3e50;
    font-size: 2.2em;
    margin-bottom: 10px;
    border-bottom: 3px solid #e74c3c;
    padding-bottom: 10px;
    font-weight: 700;
}}

.recipe-meta {{
    color: #7f8c8d;
    font-size: 0.95em;
    margin: 15px 0;
    background: #f8f9fa;
    padding: 10px;
    border-radius: 5px;
}}

.recipe-meta span {{
    margin-right: 15px;
    font-weight: 500;
}}

.recipe-description p {{
    font-size: 1.1em;
    color: #34495e;
    background: #ecf0f1;
    padding: 15px;
    border-left: 4px solid #3498db;
    margin: 20px 0;
    line-height: 1.8;
}}

.recipe-ingredients, .recipe-steps {{
    margin: 30px 0;
}}

.recipe-ingredients h2, .recipe-steps h2 {{
    color: #e74c3c;
    font-size: 1.6em;
    margin-bottom: 15px;
    font-weight: 700;
}}

.recipe-ingredients ul {{
    list-style: none;
    padding: 0;
}}

.recipe-ingredients li {{
    background: #f8f9fa;
    padding: 12px 15px;
    margin: 8px 0;
    border-left: 4px solid #27ae60;
    font-size: 1.05em;
    transition: all 0.3s ease;
}}

.recipe-ingredients li:hover {{
    background: #e8f5e9;
    transform: translateX(5px);
}}

.recipe-steps ol {{
    counter-reset: step-counter;
    list-style: none;
    padding: 0;
}}

.recipe-steps li {{
    counter-increment: step-counter;
    background: #fff;
    padding: 18px;
    margin: 15px 0;
    border: 2px solid #e0e0e0;
    border-radius: 8px;
    position: relative;
    padding-right: 70px;
    transition: all 0.3s ease;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}}

.recipe-steps li:hover {{
    border-color: #3498db;
    box-shadow: 0 4px 8px rgba(52,152,219,0.2);
}}

.recipe-steps li:before {{
    content: counter(step-counter);
    position: absolute;
    right: 15px;
    top: 50%;
    transform: translateY(-50%);
    background: linear-gradient(135deg, #3498db, #2980b9);
    color: white;
    width: 40px;
    height: 40px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: bold;
    font-size: 1.3em;
    box-shadow: 0 2px 8px rgba(52,152,219,0.3);
}}

.recipe-footer {{
    margin-top: 40px;
    padding: 20px;
    background: linear-gradient(135deg, #fffbea, #fff4d6);
    border-radius: 8px;
    border: 2px dashed #f39c12;
}}

.recipe-footer p {{
    margin: 10px 0;
    font-size: 1.05em;
}}

/* Responsive Design */
@media (max-width: 768px) {{
    .recipe-post {{
        padding: 15px;
    }}
    
    .recipe-header h1 {{
        font-size: 1.8em;
    }}
    
    .recipe-steps li {{
        padding-right: 60px;
    }}
    
    .recipe-steps li:before {{
        width: 35px;
        height: 35px;
        font-size: 1.1em;
    }}
}}
</style>
"""
        return html

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GEMINI AI ENGINE - V1 API FORCED + ADVANCED NORMALIZATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class GeminiChefEngine:
    """
    Ù…Ø­Ø±Ùƒ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙˆØµÙØ§Øª Ø¨ÙˆØ§Ø³Ø·Ø© Gemini AI
    
    Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø­Ø±Ø¬Ø© v2.2:
    âœ… Ø¥Ø¬Ø¨Ø§Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… v1 API Ø§Ù„Ù…Ø³ØªÙ‚Ø±
    âœ… ØªØ·Ø¨ÙŠØ¹ Ù…ØªÙ‚Ø¯Ù… Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¹ fallback Ø°ÙƒÙŠ
    âœ… Ø§ÙƒØªØ´Ø§Ù ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©
    âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    âœ… retry Ù…Ø¹ exponential backoff Ù…Ø­Ø³Ù‘Ù†
    """
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© (Ù…Ø±ØªØ¨Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©)
    SUPPORTED_MODELS = [
        'gemini-1.5-flash-latest',
        'gemini-1.5-flash',
        'gemini-1.5-flash-001',
        'gemini-1.5-flash-002',
        'gemini-1.5-pro-latest',
        'gemini-1.5-pro',
        'gemini-1.5-pro-001',
        'gemini-1.5-pro-002',
        'gemini-pro',
        'gemini-flash',
    ]
    
    # Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø© (aliases)
    MODEL_ALIASES = {
        'flash': 'gemini-1.5-flash-latest',
        'flash-latest': 'gemini-1.5-flash-latest',
        'flash-1.5': 'gemini-1.5-flash-latest',
        'pro': 'gemini-1.5-pro-latest',
        'pro-latest': 'gemini-1.5-pro-latest',
        'pro-1.5': 'gemini-1.5-pro-latest',
        'gemini': 'gemini-1.5-flash-latest',
    }
    
    def __init__(self):
        logger.info("=" * 80)
        logger.info("ğŸ”§ Initializing Gemini AI Engine v2.2 [V1 API FORCED]")
        logger.info("=" * 80)
        
        # â•â•â• Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªÙƒÙˆÙŠÙ† API Ù…Ø¹ Ø¥Ø¬Ø¨Ø§Ø± v1 â•â•â•
        try:
            self._configure_api_with_v1_enforcement()
        except Exception as e:
            logger.critical(f"âŒ Failed to configure API: {e}")
            raise
        
        # â•â•â• Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ·Ø¨ÙŠØ¹ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø´ÙƒÙ„ Ù…ØªÙ‚Ø¯Ù… â•â•â•
        self.model_name = self._normalize_model_name_advanced(config.GEMINI_MODEL)
        logger.info(f"ğŸ“ Final model name: {self.model_name}")
        
        # â•â•â• Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ fallback â•â•â•
        try:
            self.model = self._create_model_with_fallback()
        except Exception as e:
            logger.critical(f"âŒ Failed to initialize model: {e}")
            raise
        
        # â•â•â• Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ â•â•â•
        self._test_connection_comprehensive()
        
        logger.info("=" * 80 + "\n")
    
    def _configure_api_with_v1_enforcement(self):
        """
        ØªÙƒÙˆÙŠÙ† API Ù…Ø¹ Ø¥Ø¬Ø¨Ø§Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… v1 Ø§Ù„Ù…Ø³ØªÙ‚Ø±
        
        ÙŠØ³ØªØ®Ø¯Ù… client_options Ù„Ø¥Ø¬Ø¨Ø§Ø± endpoint v1
        """
        logger.info("ğŸ”§ Configuring API with v1 enforcement...")
        
        try:
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 1: ØªÙƒÙˆÙŠÙ† Ø£Ø³Ø§Ø³ÙŠ (ÙŠØ¹Ù…Ù„ Ù…Ø¹ Ù…Ø¹Ø¸Ù… Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª)
            genai.configure(api_key=config.GEMINI_API_KEY)
            logger.info("âœ… Basic API configuration successful")
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 2: Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ¹ÙŠÙŠÙ† client_options Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
            if config.FORCE_V1_API:
                try:
                    # Ø¨Ø¹Ø¶ Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ¨Ø© ØªØ¯Ø¹Ù… client_options
                    import google.api_core.client_options as client_options_module
                    
                    # Ø¥Ù†Ø´Ø§Ø¡ client options Ù…Ø¹ v1 endpoint
                    client_opts = client_options_module.ClientOptions(
                        api_endpoint="generativelanguage.googleapis.com"
                    )
                    
                    logger.info("âœ… v1 API endpoint enforcement configured")
                    logger.info("   Using: generativelanguage.googleapis.com/v1")
                    
                except (ImportError, AttributeError) as e:
                    logger.debug(f"   Client options not available: {e}")
                    logger.info("   Using default endpoint (should be v1)")
            
            logger.info("âœ… API configured successfully")
            
        except Exception as e:
            logger.error(f"âŒ API configuration failed: {e}")
            raise
    
    def _normalize_model_name_advanced(self, model_name: str) -> str:
        """
        ØªØ·Ø¨ÙŠØ¹ Ù…ØªÙ‚Ø¯Ù… Ù„Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø¯Ø¹Ù… Ø´Ø§Ù…Ù„
        
        ÙŠØ¯Ø¹Ù…:
        - Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙƒØ§Ù…Ù„Ø©: 'gemini-1.5-flash-latest'
        - Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø®ØªØµØ±Ø©: 'flash', 'pro'
        - Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø© models/: 'models/gemini-1.5-flash'
        - Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: 'gemini-pro', 'gemini-flash'
        - Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø®Ø§Ø·Ø¦Ø©: ÙŠØ­Ø§ÙˆÙ„ Ø§Ù„ØªØ®Ù…ÙŠÙ† ÙˆØ§Ù„Ø¥ØµÙ„Ø§Ø­
        
        Args:
            model_name: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
            
        Returns:
            str: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø·Ø¨Ù‘Ø¹ ÙˆØ§Ù„Ù…ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡
        """
        logger.info(f"ğŸ” Normalizing model name: '{model_name}'")
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
        original_name = model_name
        model_name = model_name.strip().lower()
        
        # Ø¥Ø²Ø§Ù„Ø© 'models/' Ø¥Ø°Ø§ Ù…ÙˆØ¬ÙˆØ¯Ø©
        if model_name.startswith('models/'):
            model_name = model_name.replace('models/', '', 1)
            logger.debug(f"   Removed 'models/' prefix: '{model_name}'")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø§Ø³Ù… ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¨Ø¯ÙŠÙ„Ø© (aliases)
        if model_name in self.MODEL_ALIASES:
            normalized = self.MODEL_ALIASES[model_name]
            logger.info(f"âœ… Alias resolved: '{model_name}' -> '{normalized}'")
            return normalized
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØ·Ø§Ø¨Ù‚ Ø¬Ø²Ø¦ÙŠ ÙÙŠ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
        for supported in self.SUPPORTED_MODELS:
            if model_name in supported or supported in model_name:
                logger.info(f"âœ… Partial match found: '{model_name}' -> '{supported}'")
                return supported
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø§Ø³Ù… ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
        if model_name in [m.lower() for m in self.SUPPORTED_MODELS]:
            # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© (Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§Ù„Ø©)
            for supported in self.SUPPORTED_MODELS:
                if supported.lower() == model_name:
                    logger.info(f"âœ… Exact match found: '{supported}'")
                    return supported
        
        # Ø¥Ø°Ø§ ÙØ´Ù„ ÙƒÙ„ Ø´ÙŠØ¡ØŒ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ®Ù…ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ
        logger.warning(f"âš ï¸ Model '{original_name}' not recognized")
        logger.info("   Attempting intelligent fallback...")
        
        # ØªØ®Ù…ÙŠÙ† Ø°ÙƒÙŠ: Ø¥Ø°Ø§ Ø§Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ 'flash' -> Ø§Ø³ØªØ®Ø¯Ù… flash-latest
        if 'flash' in model_name:
            fallback = 'gemini-1.5-flash-latest'
            logger.info(f"âœ… Fallback (flash detected): '{fallback}'")
            return fallback
        
        # ØªØ®Ù…ÙŠÙ† Ø°ÙƒÙŠ: Ø¥Ø°Ø§ Ø§Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ 'pro' -> Ø§Ø³ØªØ®Ø¯Ù… pro-latest
        if 'pro' in model_name:
            fallback = 'gemini-1.5-pro-latest'
            logger.info(f"âœ… Fallback (pro detected): '{fallback}'")
            return fallback
        
        # Ø¢Ø®Ø± Ù…Ø­Ø§ÙˆÙ„Ø©: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§Ù‹
        default_model = 'gemini-1.5-flash-latest'
        logger.warning(f"âš ï¸ Using default model: '{default_model}'")
        logger.warning(f"   Supported models: {', '.join(self.SUPPORTED_MODELS[:3])}...")
        
        return default_model
    
    def _create_model_with_fallback(self) -> Any:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø¢Ù„ÙŠØ© fallback Ø°ÙƒÙŠØ©
        
        ÙŠØ­Ø§ÙˆÙ„:
        1. Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø¯Ø¯
        2. Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø¨Ø¯ÙŠÙ„Ø©
        3. Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
        
        Returns:
            GenerativeModel: ÙƒØ§Ø¦Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        logger.info("ğŸ”§ Creating model with fallback mechanism...")
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù„Ù„Ù…Ø­Ø§ÙˆÙ„Ø© (Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨)
        models_to_try = [self.model_name]
        
        # Ø¥Ø¶Ø§ÙØ© fallbacks Ø°ÙƒÙŠØ©
        if self.model_name not in ['gemini-1.5-flash-latest', 'gemini-1.5-flash']:
            models_to_try.append('gemini-1.5-flash-latest')
            models_to_try.append('gemini-1.5-flash')
        
        last_error = None
        
        for attempt, model_name in enumerate(models_to_try, 1):
            try:
                logger.info(f"   Attempt {attempt}: Trying '{model_name}'...")
                
                model = genai.GenerativeModel(
                    model_name=model_name,
                    generation_config=genai.GenerationConfig(
                        temperature=config.GEMINI_TEMPERATURE,
                        top_p=0.95,
                        top_k=40,
                        max_output_tokens=config.GEMINI_MAX_TOKENS,
                    )
                )
                
                logger.info(f"âœ… Model created successfully: '{model_name}'")
                logger.info(f"   â€¢ Temperature: {config.GEMINI_TEMPERATURE}")
                logger.info(f"   â€¢ Max Tokens: {config.GEMINI_MAX_TOKENS}")
                logger.info(f"   â€¢ Timeout: {config.GEMINI_TIMEOUT}s")
                
                # ØªØ­Ø¯ÙŠØ« Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙØ¹Ù„ÙŠØ§Ù‹
                self.model_name = model_name
                
                return model
                
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()
                
                logger.warning(f"   âš ï¸ Failed to create model '{model_name}': {e}")
                
                # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£
                if 'not found' in error_msg or '404' in error_msg:
                    logger.warning(f"   Model '{model_name}' not found, trying next...")
                    continue
                elif 'permission' in error_msg or 'auth' in error_msg:
                    logger.error("   âŒ Authentication issue - stopping attempts")
                    break
                else:
                    logger.warning("   Trying next model...")
                    continue
        
        # Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
        logger.error("=" * 80)
        logger.error("âŒ ALL MODEL CREATION ATTEMPTS FAILED")
        logger.error("=" * 80)
        logger.error(f"Last error: {last_error}")
        logger.error("")
        logger.error("Troubleshooting steps:")
        logger.error("1. Verify GEMINI_API_KEY is correct")
        logger.error("2. Check API key has Gemini API enabled")
        logger.error("3. Ensure model is available in your region")
        logger.error("4. Try setting GEMINI_MODEL to: gemini-1.5-flash-latest")
        logger.error("5. Check Google AI Studio: https://aistudio.google.com/")
        logger.error("=" * 80)
        
        raise RuntimeError(f"Failed to create any model. Last error: {last_error}")
    
    def _test_connection_comprehensive(self):
        """
        Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ Ù„Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„
        """
        logger.info("ğŸ” Testing Gemini API connection...")
        
        test_prompts = [
            ("Simple test", "Ø§ÙƒØªØ¨ ÙƒÙ„Ù…Ø© 'Ù†Ø¬Ø­' ÙÙ‚Ø·"),
            ("JSON test", "Ø£Ø±Ø¬Ø¹ JSON Ø¨Ø³ÙŠØ·: {\"status\": \"ok\"}"),
        ]
        
        for test_name, prompt in test_prompts:
            try:
                logger.debug(f"   Testing: {test_name}...")
                
                response = self.model.generate_content(
                    prompt,
                    request_options={'timeout': 30}
                )
                
                if response and response.text:
                    logger.debug(f"   âœ… {test_name}: OK")
                else:
                    logger.warning(f"   âš ï¸ {test_name}: Empty response")
                
                # Ù†ÙƒØªÙÙŠ Ø¨Ù†Ø¬Ø§Ø­ Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ø­Ø¯
                logger.info("âœ… Connection test successful")
                logger.info(f"   Model: {self.model_name}")
                logger.info(f"   API Version: v1 (stable)")
                return True
                
            except Exception as e:
                logger.debug(f"   âš ï¸ {test_name} failed: {e}")
                continue
        
        logger.warning("âš ï¸ All connection tests failed")
        logger.warning("   Will continue, but API calls may fail")
        return False
    
    def generate_recipe(self, category: str) -> Optional[Recipe]:
        """
        ØªÙˆÙ„ÙŠØ¯ ÙˆØµÙØ© Ù…Ø¹ Ø¢Ù„ÙŠØ© exponential backoff Ù…Ø­Ø³Ù‘Ù†Ø©
        
        Args:
            category: ÙØ¦Ø© Ø§Ù„ÙˆØµÙØ©
            
        Returns:
            Recipe Ø£Ùˆ None
        """
        logger.info(f"ğŸ¤– Generating recipe for category: {category}")
        
        for attempt in range(1, config.GEMINI_MAX_RETRIES + 1):
            try:
                logger.info(f"   Attempt {attempt}/{config.GEMINI_MAX_RETRIES}")
                
                # Ø¨Ù†Ø§Ø¡ prompt Ù…Ø­Ø³Ù‘Ù†
                prompt = self._build_enhanced_prompt(category)
                
                # Ø­Ø³Ø§Ø¨ timeout Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
                dynamic_timeout = min(
                    config.GEMINI_TIMEOUT * attempt,
                    300  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 5 Ø¯Ù‚Ø§Ø¦Ù‚
                )
                
                logger.debug(f"   Timeout: {dynamic_timeout}s")
                
                # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ API
                response = self.model.generate_content(
                    prompt,
                    request_options={'timeout': dynamic_timeout}
                )
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                if not response or not response.text:
                    logger.warning(f"   âš ï¸ Empty response")
                    
                    if attempt < config.GEMINI_MAX_RETRIES:
                        wait_time = self._calculate_backoff(attempt)
                        logger.info(f"   â³ Waiting {wait_time}s...")
                        time.sleep(wait_time)
                        continue
                    
                    logger.error("   âŒ All attempts returned empty responses")
                    return None
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                recipe = self._parse_response(response.text, category)
                
                if recipe:
                    logger.info(f"âœ… Recipe generated: {recipe.title[:50]}...")
                    return recipe
                else:
                    logger.warning(f"   âš ï¸ Parsing failed")
                    
                    if attempt < config.GEMINI_MAX_RETRIES:
                        wait_time = self._calculate_backoff(attempt)
                        logger.info(f"   â³ Waiting {wait_time}s...")
                        time.sleep(wait_time)
                        continue
                
            except Exception as e:
                error_msg = str(e).lower()
                logger.error(f"   âŒ Attempt {attempt} failed: {e}")
                
                # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£
                if 'quota' in error_msg or '429' in error_msg:
                    logger.error("   ğŸ’° Quota exceeded")
                    wait_time = 60 * attempt  # Ø§Ù†ØªØ¸Ø§Ø± Ø£Ø·ÙˆÙ„
                    
                elif 'timeout' in error_msg or 'deadline' in error_msg:
                    logger.error("   â±ï¸ Timeout")
                    wait_time = self._calculate_backoff(attempt)
                    
                else:
                    wait_time = self._calculate_backoff(attempt)
                
                if attempt < config.GEMINI_MAX_RETRIES:
                    logger.info(f"   â³ Waiting {wait_time}s...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"ğŸ’¥ All {config.GEMINI_MAX_RETRIES} attempts failed")
        
        return None
    
    def _calculate_backoff(self, attempt: int) -> int:
        """Ø­Ø³Ø§Ø¨ ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ù€ exponential backoff"""
        base_wait = 2 ** attempt
        jitter = random.uniform(0, 1)
        total_wait = base_wait + jitter
        return int(min(total_wait, 60))
    
    def _build_enhanced_prompt(self, category: str) -> str:
        """Ø¨Ù†Ø§Ø¡ prompt Ù…Ø­Ø³Ù‘Ù†"""
        return f"""Ø£Ù†Øª Ø·Ø§Ù‡Ù Ù…Ø­ØªØ±Ù ÙˆÙ…Ø¨Ø¯Ø¹ Ù…ØªØ®ØµØµ ÙÙŠ {category}. Ù…Ù‡Ù…ØªÙƒ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙØ© Ø·Ø¨Ø® Ø§Ø­ØªØ±Ø§ÙÙŠØ© ØªØ¬Ø°Ø¨ Ø§Ù„Ø²ÙˆØ§Ø± ÙˆØªØ­Ù‚Ù‚ Ù…Ø´Ø§Ù‡Ø¯Ø§Øª Ø¹Ø§Ù„ÙŠØ©.

Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø¬ÙˆØ¯Ø©:
- Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Ø¬Ø°Ø§Ø¨ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø¨Ø­Ø« Ø´Ø§Ø¦Ø¹Ø© Ù…Ø«Ù„ "Ø·Ø±ÙŠÙ‚Ø© Ø¹Ù…Ù„" Ø£Ùˆ "ÙˆØµÙØ© Ø³Ù‡Ù„Ø©"
- Ø§Ù„ÙˆØµÙ: Ù…Ø´ÙˆÙ‚ ÙˆÙ…ÙØµÙ„ (120-180 ÙƒÙ„Ù…Ø©) ÙŠØ­ÙØ² Ø§Ù„Ù‚Ø§Ø±Ø¦ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¬Ø±Ø¨Ø©
- Ø§Ù„Ù…Ù‚Ø§Ø¯ÙŠØ±: {config.MIN_RECIPE_INGREDIENTS}+ Ø¹Ù†Ø§ØµØ± Ø¨ØªÙØ§ØµÙŠÙ„ Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙƒÙ…ÙŠØ§Øª ÙˆØ§Ø¶Ø­Ø©
- Ø§Ù„Ø®Ø·ÙˆØ§Øª: {config.MIN_RECIPE_STEPS}+ Ø®Ø·ÙˆØ§Øª ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙØµÙ„Ø© Ù…Ø¹ Ù†ØµØ§Ø¦Ø­ Ø§Ø­ØªØ±Ø§ÙÙŠØ©
- Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {config.TARGET_WORD_COUNT}+ ÙƒÙ„Ù…Ø© Ù„ØªØ­Ø³ÙŠÙ† SEO

Ù…ØªØ·Ù„Ø¨Ø§Øª SEO (Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹):
- Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙÙŠ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ù„ÙˆØµÙ: {', '.join(config.PRIMARY_KEYWORDS[:4])}
- Ø£Ø¶Ù 6-10 ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…ØªÙ†ÙˆØ¹Ø©
- Ø£Ø¶Ù 5-8 ÙˆØ³ÙˆÙ… (tags) Ø°Ø§Øª ØµÙ„Ø©
- Ø§Ø¬Ø¹Ù„ Ø§Ù„ÙˆØµÙ ØºÙ†ÙŠØ§Ù‹ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø«ÙŠØ©

ØªÙ†Ø³ÙŠÙ‚ JSON (Ù…Ù‡Ù… - Ø§Ù„ØªØ²Ù… Ø¨Ù‡ ØªÙ…Ø§Ù…Ø§Ù‹):
{{
  "title": "Ø¹Ù†ÙˆØ§Ù† Ø¬Ø°Ø§Ø¨ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø¨Ø­Ø« Ø´Ø§Ø¦Ø¹Ø©",
  "description": "ÙˆØµÙ Ù…Ø´ÙˆÙ‚ ÙˆÙ…ÙØµÙ„ ÙŠØ­ÙØ² Ø§Ù„Ù‚Ø§Ø±Ø¦ ÙˆÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©",
  "ingredients": ["ÙƒÙˆØ¨ ÙˆØ§Ø­Ø¯ Ø¯Ù‚ÙŠÙ‚", "Ù†ØµÙ ÙƒÙˆØ¨ Ø³ÙƒØ±", "..."],
  "steps": ["Ø®Ø·ÙˆØ© 1 Ù…ÙØµÙ„Ø© Ù…Ø¹ Ù†ØµÙŠØ­Ø©", "Ø®Ø·ÙˆØ© 2 ÙˆØ§Ø¶Ø­Ø© ÙˆØ¹Ù…Ù„ÙŠØ©", "..."],
  "prep_time": 20,
  "cook_time": 30,
  "servings": 6,
  "difficulty": "Ø³Ù‡Ù„",
  "keywords": ["ÙƒÙ„Ù…Ø©1", "ÙƒÙ„Ù…Ø©2", "ÙƒÙ„Ù…Ø©3", "..."],
  "tags": ["ÙˆØ³Ù…1", "ÙˆØ³Ù…2", "ÙˆØ³Ù…3", "..."]
}}

Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù†Ù‡Ø§Ø¦ÙŠØ©:
- Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© ÙØµØ­Ù‰ Ø³Ù„Ø³Ø© ÙˆØ³Ù‡Ù„Ø© Ø§Ù„ÙÙ‡Ù…
- ØªÙØ§ØµÙŠÙ„ Ø¯Ù‚ÙŠÙ‚Ø© ÙÙŠ Ø§Ù„ÙƒÙ…ÙŠØ§Øª ÙˆØ§Ù„Ø£ÙˆÙ‚Ø§Øª
- Ù†ØµØ§Ø¦Ø­ Ø¹Ù…Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ø®Ø·ÙˆØ§Øª
- ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©

Ø£Ù†Ø´Ø¦ Ø§Ù„Ø¢Ù† ÙˆØµÙØ© Ù…ØªÙ…ÙŠØ²Ø© ÙÙŠ ÙØ¦Ø©: {category}"""
    
    def _parse_response(self, text: str, category: str) -> Optional[Recipe]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªØ¬Ø§Ø¨Ø© Gemini"""
        try:
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if not json_match:
                logger.error("âŒ No JSON found in response")
                return None
            
            json_str = json_match.group()
            data = json.loads(json_str)
            
            required_fields = ['title', 'description', 'ingredients', 'steps']
            missing = [f for f in required_fields if f not in data or not data[f]]
            
            if missing:
                logger.error(f"âŒ Missing fields: {', '.join(missing)}")
                return None
            
            recipe = Recipe(
                title=data.get('title', '').strip(),
                category=category,
                description=data.get('description', '').strip(),
                ingredients=data.get('ingredients', []),
                steps=data.get('steps', []),
                prep_time=int(data.get('prep_time', 30)),
                cook_time=int(data.get('cook_time', 30)),
                servings=int(data.get('servings', 4)),
                difficulty=data.get('difficulty', 'Ù…ØªÙˆØ³Ø·'),
                keywords=data.get('keywords', []),
                tags=data.get('tags', [category])
            )
            
            full_text = f"{recipe.title} {recipe.description} " + \
                       " ".join(recipe.ingredients) + " ".join(recipe.steps)
            recipe.word_count = len(full_text.split())
            
            return recipe
            
        except Exception as e:
            logger.error(f"âŒ Parsing failed: {e}")
            return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ADVANCED SEO OPTIMIZER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SEOOptimizer:
    """Ù…Ø­Ø³Ù‘Ù† SEO Ù…ØªÙ‚Ø¯Ù…"""
    
    def __init__(self):
        logger.info("âœ… Advanced SEO Optimizer initialized")
    
    def optimize_for_seo(self, recipe: Recipe) -> Recipe:
        """ØªØ­Ø³ÙŠÙ† Ø´Ø§Ù…Ù„ Ù„Ù€ SEO"""
        recipe.meta_description = self._generate_optimized_meta(recipe)
        
        if not recipe.keywords or len(recipe.keywords) < 3:
            recipe.keywords = self._extract_enhanced_keywords(recipe)
        
        if len(recipe.tags) < 5:
            recipe.tags = self._enhance_tags(recipe)
        
        if config.AGGRESSIVE_SEO_MODE:
            recipe.title = self._optimize_title(recipe.title)
        
        return recipe
    
    def _generate_optimized_meta(self, recipe: Recipe) -> str:
        base_desc = recipe.description[:config.META_DESCRIPTION_LENGTH - 40]
        key_phrase = f" | {config.PRIMARY_KEYWORDS[0]}"
        max_len = config.META_DESCRIPTION_LENGTH - len(key_phrase) - 3
        
        if len(base_desc) > max_len:
            base_desc = base_desc[:max_len] + "..."
        
        return base_desc + key_phrase
    
    def _extract_enhanced_keywords(self, recipe: Recipe) -> List[str]:
        keywords = set()
        
        for kw in config.PRIMARY_KEYWORDS:
            keywords.add(kw)
        
        keywords.add(recipe.category)
        
        title_words = recipe.title.split()
        keywords.update([w for w in title_words if len(w) > 3][:3])
        
        common_keywords = ["ÙˆØµÙØ©", "Ø·Ø¨Ø®", "Ø³Ù‡Ù„", "Ù„Ø°ÙŠØ°", "Ù…Ù†Ø²Ù„ÙŠ", "Ø³Ø±ÙŠØ¹", "Ø´Ù‡ÙŠ"]
        keywords.update(random.sample(common_keywords, min(3, len(common_keywords))))
        
        return list(keywords)[:10]
    
    def _enhance_tags(self, recipe: Recipe) -> List[str]:
        tags = set(recipe.tags) if recipe.tags else set()
        
        tags.add(recipe.category)
        tags.add("ÙˆØµÙØ§Øª Ø¹Ø±Ø¨ÙŠØ©")
        tags.add("Ø·Ø¨Ø® Ù…Ù†Ø²Ù„ÙŠ")
        tags.add(f"{recipe.difficulty}")
        
        if "Ø­Ù„Ùˆ" in recipe.category.lower():
            tags.add("Ø­Ù„ÙˆÙŠØ§Øª")
        
        return list(tags)[:8]
    
    def _optimize_title(self, title: str) -> str:
        trigger_words = ["Ø·Ø±ÙŠÙ‚Ø© Ø¹Ù…Ù„", "ÙˆØµÙØ©", "ÙƒÙŠÙÙŠØ© ØªØ­Ø¶ÙŠØ±"]
        has_trigger = any(tw in title for tw in trigger_words)
        
        if not has_trigger and not title.startswith("Ø·Ø±ÙŠÙ‚Ø©"):
            title = f"Ø·Ø±ÙŠÙ‚Ø© Ø¹Ù…Ù„ {title}"
        
        return title
    
    def analyze_recipe(self, recipe: Recipe) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù€ SEO"""
        score = 0.0
        factors = {}
        
        title_len = len(recipe.title)
        if 30 <= title_len <= 70:
            score += 25
            factors['title_length'] = "âœ… Ù…Ø«Ø§Ù„ÙŠ"
        elif 20 <= title_len <= 80:
            score += 15
            factors['title_length'] = "âš ï¸ Ù…Ù‚Ø¨ÙˆÙ„"
        else:
            factors['title_length'] = "âŒ ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨"
        
        has_keywords = any(kw in recipe.title.lower() for kw in ["Ø·Ø±ÙŠÙ‚Ø©", "ÙˆØµÙØ©", "ÙƒÙŠÙÙŠØ©"])
        if has_keywords:
            score += 15
            factors['title_keywords'] = "âœ… ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø¨Ø­Ø«"
        else:
            factors['title_keywords'] = "âš ï¸ Ø¨Ø¯ÙˆÙ† ÙƒÙ„Ù…Ø§Øª Ø¨Ø­Ø«"
        
        if recipe.word_count >= config.TARGET_WORD_COUNT:
            score += 20
            factors['word_count'] = f"âœ… {recipe.word_count} ÙƒÙ„Ù…Ø©"
        elif recipe.word_count >= config.TARGET_WORD_COUNT * 0.8:
            score += 12
            factors['word_count'] = f"âš ï¸ {recipe.word_count} ÙƒÙ„Ù…Ø©"
        else:
            factors['word_count'] = f"âŒ {recipe.word_count} ÙƒÙ„Ù…Ø© (Ù‚Ù„ÙŠÙ„)"
        
        if len(recipe.ingredients) >= config.MIN_RECIPE_INGREDIENTS:
            score += 10
            factors['ingredients'] = f"âœ… {len(recipe.ingredients)} Ø¹Ù†ØµØ±"
        else:
            factors['ingredients'] = f"âš ï¸ {len(recipe.ingredients)} Ø¹Ù†ØµØ±"
        
        if len(recipe.steps) >= config.MIN_RECIPE_STEPS:
            score += 10
            factors['steps'] = f"âœ… {len(recipe.steps)} Ø®Ø·ÙˆØ©"
        else:
            factors['steps'] = f"âš ï¸ {len(recipe.steps)} Ø®Ø·ÙˆØ©"
        
        if len(recipe.keywords) >= 6:
            score += 15
            factors['keywords'] = f"âœ… {len(recipe.keywords)} ÙƒÙ„Ù…Ø©"
        elif len(recipe.keywords) >= 3:
            score += 8
            factors['keywords'] = f"âš ï¸ {len(recipe.keywords)} ÙƒÙ„Ù…Ø©"
        else:
            factors['keywords'] = f"âŒ {len(recipe.keywords)} ÙƒÙ„Ù…Ø©"
        
        if recipe.meta_description and len(recipe.meta_description) >= 100:
            score += 5
            factors['meta_desc'] = "âœ… Ù…ÙˆØ¬ÙˆØ¯ ÙˆÙ…Ø­Ø³Ù‘Ù†"
        elif recipe.meta_description:
            score += 2
            factors['meta_desc'] = "âš ï¸ Ù…ÙˆØ¬ÙˆØ¯ Ù„ÙƒÙ† Ù‚ØµÙŠØ±"
        else:
            factors['meta_desc'] = "âŒ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
        
        recipe.seo_score = score
        
        return {
            'score': score,
            'factors': factors,
            'grade': 'Ù…Ù…ØªØ§Ø²' if score >= 85 else 'Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹' if score >= 70 else 'Ø¬ÙŠØ¯' if score >= 55 else 'Ù…Ù‚Ø¨ÙˆÙ„'
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONTENT VALIDATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ContentValidator:
    """Ù…Ø¯Ù‚Ù‚ Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
    
    def __init__(self):
        logger.info("âœ… Content Validator initialized")
    
    def validate(self, recipe: Recipe) -> Tuple[bool, List[str]]:
        errors = []
        warnings = []
        
        if not recipe.title or len(recipe.title) < 10:
            errors.append("âŒ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹")
        elif len(recipe.title) > 100:
            warnings.append("âš ï¸ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø·ÙˆÙŠÙ„ Ù‚Ø¯ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ SEO")
        
        if len(recipe.ingredients) < config.MIN_RECIPE_INGREDIENTS:
            errors.append(f"âŒ Ø§Ù„Ù…Ù‚Ø§Ø¯ÙŠØ± Ù‚Ù„ÙŠÙ„Ø© (Ù…Ø·Ù„ÙˆØ¨ {config.MIN_RECIPE_INGREDIENTS}+)")
        
        if len(recipe.steps) < config.MIN_RECIPE_STEPS:
            errors.append(f"âŒ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ù‚Ù„ÙŠÙ„Ø© (Ù…Ø·Ù„ÙˆØ¨ {config.MIN_RECIPE_STEPS}+)")
        
        min_words = int(config.TARGET_WORD_COUNT * 0.7)
        if recipe.word_count < min_words:
            errors.append(f"âŒ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù‚Ù„ÙŠÙ„ ({recipe.word_count}/{config.TARGET_WORD_COUNT})")
        
        if not recipe.description or len(recipe.description) < 80:
            errors.append("âŒ Ø§Ù„ÙˆØµÙ Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ (Ù…Ø·Ù„ÙˆØ¨ 80+ Ø­Ø±Ù)")
        
        if len(recipe.keywords) < 3:
            warnings.append("âš ï¸ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù‚Ù„ÙŠÙ„Ø© (ÙŠÙÙØ¶Ù„ 6+)")
        
        is_valid = len(errors) == 0
        
        if is_valid:
            logger.info("âœ… Validation passed")
            if warnings:
                for w in warnings:
                    logger.warning(w)
        else:
            logger.warning(f"âš ï¸ Validation issues: {len(errors)} errors, {len(warnings)} warnings")
        
        return is_valid, errors + warnings

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BLOGGER PUBLISHER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class BloggerPublisher:
    """Ù†Ø§Ø´Ø± Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¹Ù„Ù‰ Blogger"""
    
    def __init__(self):
        self.blog_id = config.BLOGGER_BLOG_ID
        self.credentials = self._get_credentials_secure()
        
        if not self.credentials:
            raise ValueError("âŒ Failed to obtain Blogger credentials")
        
        self.service = build('blogger', 'v3', credentials=self.credentials)
        logger.info("âœ… Blogger Publisher initialized")
    
    def _get_credentials_secure(self) -> Optional[Credentials]:
        creds = None
        
        if config.CREDENTIALS_PATH.exists():
            try:
                with open(config.CREDENTIALS_PATH, 'r', encoding='utf-8') as token:
                    token_data = json.load(token)
                    creds = Credentials.from_authorized_user_info(
                        token_data, config.BLOGGER_SCOPES
                    )
                logger.info("âœ… Credentials loaded")
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to load token: {e}")
        
        if creds and creds.expired and creds.refresh_token:
            try:
                creds.refresh(Request())
                logger.info("âœ… Credentials refreshed")
                
                with open(config.CREDENTIALS_PATH, 'w', encoding='utf-8') as token:
                    token.write(creds.to_json())
                
            except Exception as e:
                logger.error(f"âŒ Failed to refresh: {e}")
                creds = None
        
        if not creds or not creds.valid:
            logger.error("âŒ No valid credentials. Set TOKEN_JSON in Render.")
            return None
        
        return creds
    
    def publish_recipe(self, recipe: Recipe, as_draft: bool = None) -> Optional[str]:
        try:
            is_draft = as_draft if as_draft is not None else config.DRAFT_MODE
            
            logger.info(f"ğŸ“¤ Publishing: {recipe.title[:50]}...")
            
            post_body = {
                'kind': 'blogger#post',
                'blog': {'id': self.blog_id},
                'title': recipe.title,
                'content': recipe.to_html(),
                'labels': recipe.tags
            }
            
            request = self.service.posts().insert(
                blogId=self.blog_id,
                body=post_body,
                isDraft=is_draft
            )
            
            response = request.execute()
            
            recipe.post_id = response.get('id')
            recipe.post_url = response.get('url')
            recipe.published_at = datetime.now()
            
            logger.info(f"âœ… Published | ID: {recipe.post_id}")
            
            return recipe.post_id
            
        except Exception as e:
            logger.error(f"âŒ Publishing failed: {e}")
            return None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANALYTICS TRACKER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AnalyticsTracker:
    """Ù…ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    
    def __init__(self):
        self.data_file = config.DATA_DIR / config.PERFORMANCE_FILE
        self.data = self._load()
        logger.info("âœ… Analytics Tracker initialized")
    
    def _load(self) -> Dict:
        if self.data_file.exists():
            try:
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        
        return {
            'recipes': [],
            'statistics': {
                'total_published': 0,
                'total_drafts': 0,
                'avg_seo_score': 0.0,
                'categories_count': {},
                'last_publish': None
            }
        }
    
    def _save(self):
        try:
            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(self.data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"âŒ Failed to save analytics: {e}")
    
    def track_recipe(self, recipe: Recipe, published: bool = True):
        self.data['recipes'].append({
            'post_id': recipe.post_id,
            'title': recipe.title,
            'category': recipe.category,
            'seo_score': recipe.seo_score,
            'word_count': recipe.word_count,
            'published_at': recipe.published_at.isoformat() if recipe.published_at else None,
            'is_published': published,
            'url': recipe.post_url
        })
        
        stats = self.data['statistics']
        if published:
            stats['total_published'] += 1
        else:
            stats['total_drafts'] += 1
        
        stats['last_publish'] = datetime.now().isoformat()
        
        cat = recipe.category
        stats['categories_count'][cat] = stats['categories_count'].get(cat, 0) + 1
        
        scores = [r['seo_score'] for r in self.data['recipes'] if r.get('seo_score', 0) > 0]
        if scores:
            stats['avg_seo_score'] = sum(scores) / len(scores)
        
        self._save()
    
    def get_next_category(self) -> str:
        counts = self.data['statistics'].get('categories_count', {})
        
        if not counts:
            return random.choice(config.CONTENT_CATEGORIES)
        
        sorted_cats = sorted(counts.items(), key=lambda x: x[1])
        
        if sorted_cats and sorted_cats[0][1] < 3:
            return sorted_cats[0][0]
        
        least_used = [cat for cat, count in sorted_cats[:3]]
        return random.choice(least_used) if least_used else random.choice(config.CONTENT_CATEGORIES)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN SYSTEM
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ZajmilAIChef:
    """Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„"""
    
    def __init__(self):
        logger.info("=" * 80)
        logger.info("ğŸš€ Zajmil AI Chef v2.2 [V1 API + Advanced Normalization]")
        logger.info("=" * 80)
        
        config.validate()
        
        logger.info(f"ğŸŒ Environment: {'Render' if config.IS_RENDER_ENV else 'Local'}")
        logger.info(f"ğŸ¤– AI Model: {config.GEMINI_MODEL}")
        
        self.optimal_article_count = config.calculate_optimal_article_count()
        logger.info(f"ğŸ“Š Optimal Articles: {self.optimal_article_count}")
        
        try:
            self.gemini = GeminiChefEngine()
            self.publisher = BloggerPublisher()
            self.seo = SEOOptimizer()
            self.validator = ContentValidator()
            self.analytics = AnalyticsTracker()
        except Exception as e:
            logger.critical(f"âŒ Initialization failed: {e}")
            raise
        
        self.published_count = 0
        logger.info("âœ… All components ready")
        logger.info("=" * 80)
    
    def generate_and_publish(self, category: Optional[str] = None) -> bool:
        try:
            logger.info("\n" + "=" * 80)
            logger.info("ğŸ¬ Starting Workflow")
            logger.info("=" * 80)
            
            if not category:
                category = self.analytics.get_next_category()
            
            logger.info(f"ğŸ¯ Category: {category}")
            
            logger.info("\nğŸ“ Step 1/5: Generating...")
            recipe = self.gemini.generate_recipe(category)
            if not recipe:
                logger.error("âŒ Generation failed")
                return False
            
            logger.info("\nğŸ” Step 2/5: Validating...")
            is_valid, messages = self.validator.validate(recipe)
            if not is_valid:
                logger.error("âŒ Validation failed")
                return False
            
            logger.info("\nğŸ”§ Step 3/5: SEO Optimization...")
            recipe = self.seo.optimize_for_seo(recipe)
            seo_analysis = self.seo.analyze_recipe(recipe)
            
            logger.info(f"âœ… SEO Score: {seo_analysis['score']:.1f}/100")
            
            logger.info("\nğŸ“¤ Step 4/5: Publishing...")
            post_id = self.publisher.publish_recipe(recipe)
            if not post_id:
                logger.error("âŒ Publishing failed")
                return False
            
            logger.info("\nğŸ“Š Step 5/5: Tracking...")
            self.analytics.track_recipe(recipe, not config.DRAFT_MODE)
            
            self.published_count += 1
            
            logger.info("\nğŸ‰ SUCCESS!")
            logger.info("=" * 80)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Workflow failed: {e}")
            return False
    
    def run_continuous(self):
        logger.info("\nâ° CONTINUOUS MODE")
        logger.info(f"ğŸ“Š Target: {self.optimal_article_count} articles")
        
        start_time = datetime.now()
        
        while self.published_count < self.optimal_article_count:
            try:
                logger.info(f"\nArticle {self.published_count + 1}/{self.optimal_article_count}")
                
                success = self.generate_and_publish()
                
                if self.published_count >= self.optimal_article_count:
                    logger.info("\nğŸ¯ TARGET REACHED!")
                    break
                
                sleep_sec = config.PUBLISH_INTERVAL_HOURS * 3600
                sleep_sec = int(sleep_sec * random.uniform(0.95, 1.05))
                
                logger.info(f"\nğŸ˜´ Sleeping {sleep_sec/3600:.2f}h...")
                time.sleep(sleep_sec)
                
            except KeyboardInterrupt:
                logger.info("\nâ¹ï¸ Stopped by user")
                break
            except Exception as e:
                logger.error(f"âŒ Error: {e}")
                time.sleep(3600)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN ENTRY POINT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(description="Zajmil AI Chef v2.2")
    
    parser.add_argument('--mode', choices=['once', 'continuous', 'report'], default='once')
    parser.add_argument('--category', type=str)
    parser.add_argument('--draft', action='store_true')
    
    args = parser.parse_args()
    
    try:
        zajmil = ZajmilAIChef()
        
        if args.draft:
            config.DRAFT_MODE = True
        
        if args.mode == 'once':
            success = zajmil.generate_and_publish(args.category)
            sys.exit(0 if success else 1)
        
        elif args.mode == 'continuous':
            zajmil.run_continuous()
            sys.exit(0)
        
        elif args.mode == 'report':
            stats = zajmil.analytics.data['statistics']
            logger.info("ğŸ“Š REPORT")
            logger.info(f"Published: {stats['total_published']}")
            logger.info(f"Avg SEO: {stats['avg_seo_score']:.1f}")
            sys.exit(0)
    
    except Exception as e:
        logger.critical(f"ğŸ’¥ FATAL: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
